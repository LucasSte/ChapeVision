{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to find goalposts and the ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Reshape, Flatten, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "#from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import bisect\n",
    "from os.path import basename\n",
    "import xml.etree.ElementTree\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reduzida25_skip(input_size, cosize):\n",
    "\n",
    "    input_image = Input(shape=(input_size, cosize, 3))\n",
    "\n",
    "    # Layer 1\n",
    "    x = Conv2D(4, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x = Conv2D(8, (3,3), strides=(1,1), padding='same', name='conv_' + str(0+2), use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_' + str(0+2))(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    \n",
    "        # Layer 2 - 5\n",
    "    for i in range(1,4):\n",
    "        x = Conv2D(4*(2**i), (3,3), strides=(1,1), padding='same', name='conv_' + str(i+2), use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_' + str(i+2))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        # Layer 6\n",
    "    x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    skip_connection = x\n",
    "\n",
    "        # Layer 7 - 8\n",
    "    for i in range(0,2):\n",
    "        x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_' + str(i+7), use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_' + str(i+7))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "    skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_skip', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    #skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "    x = concatenate([skip_connection, x])\n",
    "        \n",
    "        \n",
    "    x = Conv2D(10, (1,1), strides = (1,1), padding = 'same', name = 'conv_9', use_bias = True)(x)\n",
    "        \n",
    "    model = Model(inputs = input_image, outputs=x, name='Fast')\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minha2_skip_pequena(input_size, cosize):\n",
    "\n",
    "    input_image = Input(shape=(input_size, cosize, 3))\n",
    "\n",
    "    # Layer 1\n",
    "    #Originalmente era quatro, mas coloquei oito\n",
    "    x = Conv2D(8, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = Conv2D(8*(2**0), (3,3), strides=(1,1), padding='same', name='conv_' + str(2), use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_' + str(2))(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "        # Layer 2 - 5\n",
    "    for i in range(1,4):\n",
    "        x = Conv2D(8*(2**i), (3,3), strides=(1,1), padding='same', name='conv_' + str(i+2), use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_' + str(i+2))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        # Layer 6\n",
    "    x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    skip_connection = x\n",
    "\n",
    "        # Layer 7 - 8\n",
    "    for i in range(0,2):\n",
    "        x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_' + str(i+7), use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_' + str(i+7))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "    skip_connection = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_skip', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    #skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "    x = concatenate([skip_connection, x])\n",
    "        \n",
    "        \n",
    "    x = Conv2D(10, (1,1), strides = (1,1), padding = 'same', name = 'conv_9', use_bias = True)(x)\n",
    "        \n",
    "    model = Model(inputs = input_image, outputs=x, name='Fast')\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minha2_skip_pequena2(input_size, cosize):\n",
    "\n",
    "    input_image = Input(shape=(input_size, cosize, 3))\n",
    "\n",
    "    # Layer 1\n",
    "    #Originalmente era quatro, mas coloquei oito\n",
    "    x = Conv2D(8, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "    x = BatchNormalization(name='norm_1')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    x = Conv2D(8*(2**0), (3,3), strides=(1,1), padding='same', name='conv_' + str(2), use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_' + str(2))(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "        # Layer 2 - 5\n",
    "    for i in range(1,4):\n",
    "        x = Conv2D(8*(2**i), (3,3), strides=(1,1), padding='same', name='conv_' + str(i+2), use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_' + str(i+2))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        # Layer 6\n",
    "    x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='norm_6')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    skip_connection = x\n",
    "\n",
    "        # Layer 7 - 8\n",
    "    for i in range(0,2):\n",
    "        x = Conv2D(128*2**(i), (3,3), strides=(1,1), padding='same', name='conv_' + str(i+7), use_bias=False)(x)\n",
    "        x = BatchNormalization(name='norm_' + str(i+7))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        \n",
    "    skip_connection = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_skip', use_bias=False)(skip_connection)\n",
    "    skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "    skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "    #skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "    x = concatenate([skip_connection, x])\n",
    "        \n",
    "        \n",
    "    x = Conv2D(10, (1,1), strides = (1,1), padding = 'same', name = 'conv_9', use_bias = True)(x)\n",
    "        \n",
    "    model = Model(inputs = input_image, outputs=x, name='Fast')\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede = minha2_skip_pequena(120,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasta_atual = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metodo3(pasta):  #trave com dimensoes\n",
    "    \n",
    "    nomesdearquivos = glob.glob(pasta + '/*.xml')\n",
    "    fotos = glob.glob(pasta + '/*.png')\n",
    "    maisfotos = glob.glob(pasta+ '/*.jpg')\n",
    "    for nome in maisfotos:\n",
    "        fotos.append(nome)\n",
    "    fotosjpeg = glob.glob(pasta + '/*.jpeg')\n",
    "    for nome in fotosjpeg:\n",
    "        fotos.append(nome)\n",
    "    fotosJPG = glob.glob(pasta + '/*.JPG')\n",
    "    for nome in fotosJPG:\n",
    "        fotos.append(nome)\n",
    "    nomesdearquivos.sort()\n",
    "    fotos.sort()\n",
    "    nomesdasanotacoes = list()\n",
    "    for nomeindo in nomesdearquivos:\n",
    "        bisect.insort(nomesdasanotacoes, basename(nomeindo).split('.')[0])\n",
    "        \n",
    "    \n",
    "    para_imprimir = list()\n",
    "    entrada = list()\n",
    "    for nome in nomesdasanotacoes:\n",
    "        e = xml.etree.ElementTree.parse(pasta+'/'+nome+'.xml').getroot()\n",
    "        objects = e.findall('object')           \n",
    "        \n",
    "        resposta = np.zeros((15,20,10), dtype=float)\n",
    "        \n",
    "        ball = None\n",
    "        goalpost = None\n",
    "        goalpost_2 = None\n",
    "        \n",
    "        if objects is None:\n",
    "            para_imprimir.append(resposta)\n",
    "        else:\n",
    "            tam = len(objects)\n",
    "            for i in range(0, tam):\n",
    "                if objects[i][0].text == 'ball':\n",
    "                    ball = objects[i]\n",
    "                elif objects[i][0].text == 'goalpost':\n",
    "                    goalpost = objects[i]\n",
    "                elif objects[i][0].text == 'goalpost_2':\n",
    "                    goalpost_2 = objects[i]\n",
    "            \n",
    "            \n",
    "        if ball is not None:\n",
    "                \n",
    "            ball_xmin = float(ball[4][0].text)/4\n",
    "            ball_ymin = float(ball[4][1].text)/4\n",
    "            ball_xmax = float(ball[4][2].text)/4\n",
    "            ball_ymax = float(ball[4][3].text)/4\n",
    "                \n",
    "            ball_Xc = (ball_xmin + ball_xmax)/2\n",
    "            ball_posicx = int((ball_Xc)/8)\n",
    "            ball_Xc = ball_Xc - ball_posicx*8\n",
    "            ball_Xc = ball_Xc/8\n",
    "            ball_Yc = (ball_ymin + ball_ymax)/2\n",
    "            ball_posicy = int((ball_Yc)/8)\n",
    "            ball_Yc = ball_Yc - ball_posicy*8\n",
    "            ball_Yc = ball_Yc/8\n",
    "            ball_largura = (ball_xmax - ball_xmin)/160\n",
    "            ball_altura = (ball_ymax - ball_ymin)/160\n",
    "                \n",
    "            resposta[ball_posicy][ball_posicx][0:5] = (1, ball_Xc, ball_Yc, ball_largura, ball_altura)\n",
    "            \n",
    "                      \n",
    "        if goalpost is not None:\n",
    "            \n",
    "            goalpost_xmin = float(goalpost[4][0].text)/4\n",
    "            goalpost_ymin = float(goalpost[4][1].text)/4\n",
    "            goalpost_xmax = float(goalpost[4][2].text)/4\n",
    "            goalpost_ymax = float(goalpost[4][3].text)/4\n",
    "            \n",
    "            goalpost_Xc = (goalpost_xmin + goalpost_xmax)/2\n",
    "            goalpost_posicx = int((goalpost_Xc)/8)\n",
    "            goalpost_Xc = goalpost_Xc - goalpost_posicx*8\n",
    "            goalpost_Xc = goalpost_Xc/8\n",
    "            goalpost_Yc = (goalpost_ymin + goalpost_ymax)/2\n",
    "            goalpost_posicy = int((goalpost_Yc)/8)\n",
    "            goalpost_Yc = goalpost_Yc - goalpost_posicy*8\n",
    "            goalpost_Yc = goalpost_Yc/8\n",
    "            goalpost_largura = (goalpost_xmax - goalpost_xmin)/160\n",
    "            goalpost_altura = (goalpost_ymax - goalpost_ymin)/160\n",
    "            \n",
    "            if goalpost_posicy > 20:\n",
    "                print(nome)\n",
    "                print('y')\n",
    "            elif goalpost_posicx > 20:\n",
    "                print(nome)\n",
    "                print('x')\n",
    "            \n",
    "            resposta[goalpost_posicy][goalpost_posicx][5:10] = (1,goalpost_Xc, goalpost_Yc, goalpost_largura, goalpost_altura)\n",
    "            #Funcao de custo esta errada, pois assim deu certo. Alem disso, escolher outra forma de \n",
    "            #marcar a trave\n",
    "        \n",
    "        if goalpost_2 is not None:\n",
    "            \n",
    "            goalpost2_xmin = float(goalpost_2[4][0].text)/4\n",
    "            goalpost2_ymin = float(goalpost_2[4][1].text)/4\n",
    "            goalpost2_xmax = float(goalpost_2[4][2].text)/4\n",
    "            goalpost2_ymax = float(goalpost_2[4][3].text)/4\n",
    "            \n",
    "            goalpost2_Xc = (goalpost2_xmin + goalpost2_xmax)/2\n",
    "            goalpost2_posicx = int((goalpost2_Xc)/8)\n",
    "            goalpost2_Xc = goalpost2_Xc - goalpost2_posicx*8\n",
    "            goalpost2_Xc = goalpost2_Xc/8\n",
    "            goalpost2_Yc = (goalpost2_ymin + goalpost2_ymax)/2\n",
    "            goalpost2_posicy = int((goalpost2_Yc)/8)\n",
    "            goalpost2_Yc = goalpost2_Yc - goalpost2_posicy*8\n",
    "            goalpost2_Yc = goalpost2_Yc/8\n",
    "            goalpost2_largura = (goalpost2_xmax - goalpost2_xmin)/160\n",
    "            goalpost2_altura = (goalpost2_ymax - goalpost2_ymin)/160\n",
    "        \n",
    "            resposta[goalpost2_posicy][goalpost2_posicx][5:10] = (1, goalpost2_Xc, goalpost2_Yc, goalpost2_largura, goalpost2_altura)\n",
    "            #Funcao de custo esta errada, pois assim deu certo. Alem disso, escolher outra forma de \n",
    "            #marcar a trave\n",
    "        \n",
    "        para_imprimir.append(resposta)\n",
    "        \n",
    "    Y = np.array(para_imprimir)\n",
    "\n",
    "    for arquivo in fotos:\n",
    "        img = cv2.imread(arquivo)\n",
    "        img = cv2.resize(img, (160,120), interpolation = cv2.INTER_AREA)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        entrada.append(img)\n",
    "        \n",
    "    \n",
    "    X = np.array(entrada)\n",
    "    X = X.astype(float)\n",
    "    X = X/255\n",
    "    \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "carregar = list()\n",
    "carregar = os.listdir(pasta_atual + '/Conjunto de Treino 2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = Metodo3(pasta_atual +'/Conjunto de Treino 2019/' + carregar[len(carregar)-1])\n",
    "carregar.pop();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pasta in carregar:\n",
    "    x1, y1 = Metodo3(pasta_atual +'/Conjunto de Treino 2019/' + pasta)\n",
    "    x = np.concatenate((x,x1), axis=0)\n",
    "    y = np.concatenate((y,y1), axis=0)\n",
    "    x1 = None\n",
    "    y1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = Metodo3(pasta_atual +'/Validation set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Formato do X', (14934, 120, 160, 3))\n",
      "('Foramto do Y', (14934, 15, 20, 10))\n"
     ]
    }
   ],
   "source": [
    "print(\"Formato do X\", x.shape)\n",
    "print(\"Foramto do Y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Formato do X_val', (1173, 120, 160, 3))\n",
      "('Foramto do Y_val', (1173, 15, 20, 10))\n"
     ]
    }
   ],
   "source": [
    "print(\"Formato do X_val\", x_val.shape)\n",
    "print(\"Foramto do Y_val\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball_goalpost_loss3(y_true, y_pred): #Trave com dimensoes\n",
    "    \n",
    "    #BALL\n",
    "    Xc_true = y_true[...,1]\n",
    "    Xc_pred = tf.sigmoid(y_pred[..., 1])        ##mudei aqui\n",
    "    Yc_true = y_true[..., 2]\n",
    "    Yc_pred = tf.sigmoid(y_pred[..., 2])        ##mudei aqui\n",
    "    W_true = tf.sqrt(tf.abs(y_true[...,3]))\n",
    "    H_true = tf.sqrt(tf.abs(y_true[...,4]))\n",
    "    WH_pred = tf.sqrt(tf.abs(tf.exp(y_pred[..., 3:5])*np.reshape(ANCHORS, [1,1,BOX,2])))\n",
    "    W_pred = WH_pred[...,0]\n",
    "    H_pred = WH_pred[...,1]\n",
    "    confidence_true = y_true[...,0]\n",
    "    confidence_pred = tf.sigmoid(y_pred[...,0])\n",
    "    class_true = y_true[...,0]\n",
    "    \n",
    "    #GOALPOST\n",
    "    Xc_true_post = y_true[...,6]\n",
    "    Xc_pred_post = tf.sigmoid(y_pred[..., 6])        ##mudei aqui\n",
    "    Yc_true_post = y_true[..., 7]\n",
    "    Yc_pred_post = tf.sigmoid(y_pred[..., 7])        ##mudei aqui\n",
    "    W_true_post = tf.sqrt(tf.abs(y_true[...,8]))\n",
    "    H_true_post = tf.sqrt(tf.abs(y_true[...,9]))\n",
    "    WH_pred_post = tf.sqrt(tf.abs(tf.exp(y_pred[..., 8:10])*np.reshape(ANCHORS_post, [1,1,BOX,2])))\n",
    "    W_pred_post = WH_pred_post[...,0]\n",
    "    H_pred_post = WH_pred_post[...,1]\n",
    "    confidence_true_post = y_true[...,5]\n",
    "    confidence_pred_post = tf.sigmoid(y_pred[...,5])\n",
    "    class_true_post = y_true[...,5]\n",
    "    \n",
    "    \n",
    "    #BALL\n",
    "    Xc_pred = tf.multiply(class_true,Xc_pred)\n",
    "    Yc_pred = tf.multiply(class_true, Yc_pred)\n",
    "    H_pred = tf.multiply(class_true, H_pred)\n",
    "    W_pred = tf.multiply(class_true, W_pred)\n",
    "    \n",
    "    \n",
    "    #GOALPOST\n",
    "    Xc_pred_post = tf.multiply(class_true_post, Xc_pred_post)\n",
    "    Yc_pred_post = tf.multiply(class_true_post, Yc_pred_post)\n",
    "    H_pred_post = tf.multiply(class_true_post, H_pred_post)\n",
    "    W_pred_post = tf.multiply(class_true_post, W_pred_post)\n",
    "    \n",
    "    #BALL\n",
    "    loss_xy = (tf.square(Xc_pred - Xc_true) + tf.square(Yc_pred - Yc_true))\n",
    "    loss_xy = 5*tf.reduce_sum(loss_xy)\n",
    "    \n",
    "    #GOALPOST    \n",
    "    loss_xy_post = (tf.square(Xc_pred_post - Xc_true_post) + tf.square(Yc_pred_post - Yc_true_post))\n",
    "    loss_xy_post = 5*tf.reduce_sum(loss_xy_post)\n",
    "    \n",
    "    #BALL\n",
    "    loss_wh = (tf.square(W_true - W_pred) + tf.square(H_pred - H_true))\n",
    "    loss_wh = 20*tf.reduce_sum(loss_wh)  #era 10\n",
    "    \n",
    "    #GOALPOST\n",
    "    loss_wh_post = (tf.square(W_true_post - W_pred_post) + tf.square(H_pred_post - H_true_post))\n",
    "    loss_wh_post = 20*tf.reduce_sum(loss_wh_post)  #era 10\n",
    "    \n",
    "    #BALL\n",
    "    no_object = 1 - class_true\n",
    "    diff_conf = tf.square(confidence_true - confidence_pred)\n",
    "    loss_no_object = (tf.multiply(diff_conf, no_object))\n",
    "    loss_no_object = 10*tf.reduce_sum(loss_no_object)  #era 0.5\n",
    "    \n",
    "    loss_object = 50*tf.reduce_sum(tf.multiply(class_true, diff_conf)) #era 5\n",
    "    \n",
    "    #GOALPOST\n",
    "    no_object_post = 1 - class_true_post\n",
    "    diff_conf_post = tf.square(confidence_true_post - confidence_pred_post)\n",
    "    loss_no_object_post = (tf.multiply(diff_conf_post, no_object_post))\n",
    "    loss_no_object_post = 10*tf.reduce_sum(loss_no_object_post)  #era 0.5\n",
    "    \n",
    "    loss_object_post = 50*tf.reduce_sum(tf.multiply(class_true_post, diff_conf_post)) #era 5\n",
    "    \n",
    "    \n",
    "    \n",
    "    #loss_class = tf.nn.sigmoid_cross_entropy_with_logits(labels = class_true, logits = class_pred)\n",
    "    #loss_class = tf.reduce_sum(loss_class)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_no_object + loss_object + loss_xy_post + loss_wh_post + loss_no_object_post + loss_object_post #loss_class\n",
    "    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14934/14934 [==============================] - 293s 20ms/step - loss: 609.9507\n",
      "Epoch 2/100\n",
      "14934/14934 [==============================] - 280s 19ms/step - loss: 173.8215\n",
      "Epoch 3/100\n",
      "14934/14934 [==============================] - 279s 19ms/step - loss: 115.0956\n",
      "Epoch 4/100\n",
      "14934/14934 [==============================] - 240s 16ms/step - loss: 89.2154\n",
      "Epoch 5/100\n",
      "14934/14934 [==============================] - 246s 17ms/step - loss: 75.3102\n",
      "Epoch 6/100\n",
      "14934/14934 [==============================] - 266s 18ms/step - loss: 65.9104\n",
      "Epoch 7/100\n",
      "14934/14934 [==============================] - 267s 18ms/step - loss: 59.0194\n",
      "Epoch 8/100\n",
      "14934/14934 [==============================] - 268s 18ms/step - loss: 54.1385\n",
      "Epoch 9/100\n",
      "14934/14934 [==============================] - 268s 18ms/step - loss: 49.6115\n",
      "Epoch 10/100\n",
      "14934/14934 [==============================] - 273s 18ms/step - loss: 46.0694\n",
      "Epoch 11/100\n",
      "14934/14934 [==============================] - 273s 18ms/step - loss: 43.1292\n",
      "Epoch 12/100\n",
      "14934/14934 [==============================] - 273s 18ms/step - loss: 40.3044\n",
      "Epoch 13/100\n",
      "14934/14934 [==============================] - 274s 18ms/step - loss: 37.9891\n",
      "Epoch 14/100\n",
      "14934/14934 [==============================] - 236s 16ms/step - loss: 35.4543\n",
      "Epoch 15/100\n",
      "14934/14934 [==============================] - 236s 16ms/step - loss: 33.8512\n",
      "Epoch 16/100\n",
      "14934/14934 [==============================] - 239s 16ms/step - loss: 31.8892\n",
      "Epoch 17/100\n",
      "14934/14934 [==============================] - 239s 16ms/step - loss: 30.6142\n",
      "Epoch 18/100\n",
      "14934/14934 [==============================] - 237s 16ms/step - loss: 28.6063\n",
      "Epoch 19/100\n",
      "14934/14934 [==============================] - 274s 18ms/step - loss: 27.6888\n",
      "Epoch 20/100\n",
      "14934/14934 [==============================] - 277s 19ms/step - loss: 26.8441\n",
      "Epoch 21/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 25.6984\n",
      "Epoch 22/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 24.5762\n",
      "Epoch 23/100\n",
      "14934/14934 [==============================] - 277s 19ms/step - loss: 23.4223\n",
      "Epoch 24/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 22.8071\n",
      "Epoch 25/100\n",
      "14934/14934 [==============================] - 277s 19ms/step - loss: 21.7081\n",
      "Epoch 26/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 21.0503\n",
      "Epoch 27/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 20.4067\n",
      "Epoch 28/100\n",
      "14934/14934 [==============================] - 276s 19ms/step - loss: 19.7791\n",
      "Epoch 29/100\n",
      "14934/14934 [==============================] - 277s 19ms/step - loss: 19.1726\n",
      "Epoch 30/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 18.4329\n",
      "Epoch 31/100\n",
      "14934/14934 [==============================] - 276s 19ms/step - loss: 17.8369\n",
      "Epoch 32/100\n",
      "14934/14934 [==============================] - 277s 19ms/step - loss: 17.3804\n",
      "Epoch 33/100\n",
      "14934/14934 [==============================] - 276s 18ms/step - loss: 17.0778\n",
      "Epoch 34/100\n",
      "14934/14934 [==============================] - 274s 18ms/step - loss: 16.6906\n",
      "Epoch 35/100\n",
      "14934/14934 [==============================] - 276s 18ms/step - loss: 16.1369\n",
      "Epoch 36/100\n",
      "14934/14934 [==============================] - 275s 18ms/step - loss: 15.4412\n",
      "Epoch 37/100\n",
      "14934/14934 [==============================] - 275s 18ms/step - loss: 15.4327\n",
      "Epoch 38/100\n",
      "14934/14934 [==============================] - 274s 18ms/step - loss: 15.2638\n",
      "Epoch 39/100\n",
      "14934/14934 [==============================] - 273s 18ms/step - loss: 14.5243\n",
      "Epoch 40/100\n",
      "14934/14934 [==============================] - 273s 18ms/step - loss: 14.2856\n",
      "Epoch 41/100\n",
      "14934/14934 [==============================] - 272s 18ms/step - loss: 14.3365\n",
      "Epoch 42/100\n",
      "14934/14934 [==============================] - 272s 18ms/step - loss: 13.6695\n",
      "Epoch 43/100\n",
      "14934/14934 [==============================] - 272s 18ms/step - loss: 13.6170\n",
      "Epoch 44/100\n",
      "14934/14934 [==============================] - 272s 18ms/step - loss: 13.0885\n",
      "Epoch 45/100\n",
      "14934/14934 [==============================] - 271s 18ms/step - loss: 12.9191\n",
      "Epoch 46/100\n",
      "14934/14934 [==============================] - 271s 18ms/step - loss: 12.7117\n",
      "Epoch 47/100\n",
      "14934/14934 [==============================] - 271s 18ms/step - loss: 12.4330\n",
      "Epoch 48/100\n",
      "14934/14934 [==============================] - 270s 18ms/step - loss: 12.2558\n",
      "Epoch 49/100\n",
      "14934/14934 [==============================] - 270s 18ms/step - loss: 11.8911\n",
      "Epoch 50/100\n",
      "14934/14934 [==============================] - 270s 18ms/step - loss: 11.9103\n",
      "Epoch 51/100\n",
      "14934/14934 [==============================] - 269s 18ms/step - loss: 11.7326\n",
      "Epoch 52/100\n",
      "14934/14934 [==============================] - 250s 17ms/step - loss: 11.2681\n",
      "Epoch 53/100\n",
      "14934/14934 [==============================] - 227s 15ms/step - loss: 11.3880\n",
      "Epoch 54/100\n",
      "14934/14934 [==============================] - 234s 16ms/step - loss: 11.1058\n",
      "Epoch 55/100\n",
      "14934/14934 [==============================] - 234s 16ms/step - loss: 11.1151\n",
      "Epoch 56/100\n",
      "14934/14934 [==============================] - 234s 16ms/step - loss: 10.9575\n",
      "Epoch 57/100\n",
      "14934/14934 [==============================] - 233s 16ms/step - loss: 10.4366\n",
      "Epoch 58/100\n",
      "14934/14934 [==============================] - 234s 16ms/step - loss: 10.2371\n",
      "Epoch 59/100\n",
      "14934/14934 [==============================] - 253s 17ms/step - loss: 10.2662\n",
      "Epoch 60/100\n",
      "14934/14934 [==============================] - 261s 18ms/step - loss: 10.1183\n",
      "Epoch 61/100\n",
      "14934/14934 [==============================] - 262s 18ms/step - loss: 10.2669\n",
      "Epoch 62/100\n",
      "14934/14934 [==============================] - 261s 18ms/step - loss: 10.0861\n",
      "Epoch 63/100\n",
      "14934/14934 [==============================] - 262s 18ms/step - loss: 9.6386\n",
      "Epoch 64/100\n",
      "14934/14934 [==============================] - 262s 18ms/step - loss: 9.8384\n",
      "Epoch 65/100\n",
      "14934/14934 [==============================] - 261s 17ms/step - loss: 9.5893\n",
      "Epoch 66/100\n",
      "14934/14934 [==============================] - 262s 18ms/step - loss: 9.3385\n",
      "Epoch 67/100\n",
      "14934/14934 [==============================] - 262s 18ms/step - loss: 9.5044\n",
      "Epoch 68/100\n",
      "14934/14934 [==============================] - 244s 16ms/step - loss: 9.3711\n",
      "Epoch 69/100\n",
      "14934/14934 [==============================] - 225s 15ms/step - loss: 9.2109\n",
      "Epoch 70/100\n",
      "14934/14934 [==============================] - 225s 15ms/step - loss: 8.9216\n",
      "Epoch 71/100\n",
      "14934/14934 [==============================] - 237s 16ms/step - loss: 8.8570\n",
      "Epoch 72/100\n",
      "14934/14934 [==============================] - 243s 16ms/step - loss: 8.8805\n",
      "Epoch 73/100\n",
      "14934/14934 [==============================] - 243s 16ms/step - loss: 8.9016\n",
      "Epoch 74/100\n",
      "14934/14934 [==============================] - 263s 18ms/step - loss: 8.5851\n",
      "Epoch 75/100\n",
      "14934/14934 [==============================] - 227s 15ms/step - loss: 8.6651\n",
      "Epoch 76/100\n",
      "14934/14934 [==============================] - 257s 17ms/step - loss: 8.6757\n",
      "Epoch 77/100\n",
      "14934/14934 [==============================] - 261s 17ms/step - loss: 8.5292\n",
      "Epoch 78/100\n",
      "14934/14934 [==============================] - 248s 17ms/step - loss: 8.2141\n",
      "Epoch 79/100\n",
      "14934/14934 [==============================] - 232s 16ms/step - loss: 8.2011\n",
      "Epoch 80/100\n",
      "14934/14934 [==============================] - 260s 17ms/step - loss: 7.8671\n",
      "Epoch 81/100\n",
      "14934/14934 [==============================] - 227s 15ms/step - loss: 8.3505\n",
      "Epoch 82/100\n",
      "14934/14934 [==============================] - 258s 17ms/step - loss: 7.7737\n",
      "Epoch 83/100\n",
      "14934/14934 [==============================] - 260s 17ms/step - loss: 7.9118\n",
      "Epoch 84/100\n",
      "14934/14934 [==============================] - 259s 17ms/step - loss: 7.9995\n",
      "Epoch 85/100\n",
      "14934/14934 [==============================] - 259s 17ms/step - loss: 7.7978\n",
      "Epoch 86/100\n",
      "14934/14934 [==============================] - 260s 17ms/step - loss: 7.7131\n",
      "Epoch 87/100\n",
      "14934/14934 [==============================] - 243s 16ms/step - loss: 7.7775\n",
      "Epoch 88/100\n",
      "14934/14934 [==============================] - 266s 18ms/step - loss: 7.5312\n",
      "Epoch 89/100\n",
      "14934/14934 [==============================] - 313s 21ms/step - loss: 7.3768\n",
      "Epoch 90/100\n",
      "14934/14934 [==============================] - 273s 18ms/step - loss: 7.5091\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14934/14934 [==============================] - 252s 17ms/step - loss: 7.3770\n",
      "Epoch 92/100\n",
      "14934/14934 [==============================] - 256s 17ms/step - loss: 7.5391\n",
      "Epoch 93/100\n",
      "14934/14934 [==============================] - 256s 17ms/step - loss: 7.4595\n",
      "Epoch 94/100\n",
      "14934/14934 [==============================] - 256s 17ms/step - loss: 7.3414\n",
      "Epoch 95/100\n",
      "14934/14934 [==============================] - 267s 18ms/step - loss: 7.2306\n",
      "Epoch 96/100\n",
      "14934/14934 [==============================] - 228s 15ms/step - loss: 7.2014\n",
      "Epoch 97/100\n",
      "14934/14934 [==============================] - 237s 16ms/step - loss: 7.1917\n",
      "Epoch 98/100\n",
      "14934/14934 [==============================] - 251s 17ms/step - loss: 7.0563\n",
      "Epoch 99/100\n",
      "14934/14934 [==============================] - 258s 17ms/step - loss: 6.9517\n",
      "Epoch 100/100\n",
      "14934/14934 [==============================] - 258s 17ms/step - loss: 6.9994\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam (lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "ANCHORS = [5,5]\n",
    "BOX = 1\n",
    "ANCHORS_post = [2,5] ##MUDAR AQUI PARA [2,5]\n",
    "\n",
    "\n",
    "rede.compile(loss=ball_goalpost_loss3, optimizer=optimizer)\n",
    "\n",
    "\n",
    "rede.fit(x, y, epochs=100, batch_size=5)\n",
    "#existe tambem o validation split\n",
    "#validantion_data = (x_val,y_val)\n",
    "rede.compile(loss=mean_squared_error, optimizer='sgd', metrics = ['accuracy'])\n",
    "rede.save(pasta_atual+ '/RedeGrande_colfax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede = Reduzida25_skip(120,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14934 samples, validate on 1173 samples\n",
      "Epoch 1/100\n",
      "14934/14934 [==============================] - 162s 11ms/step - loss: 1052.0101 - val_loss: 280.0253\n",
      "Epoch 2/100\n",
      "14934/14934 [==============================] - 173s 12ms/step - loss: 221.3559 - val_loss: 182.1973\n",
      "Epoch 3/100\n",
      "14934/14934 [==============================] - 178s 12ms/step - loss: 148.8932 - val_loss: 148.7764\n",
      "Epoch 4/100\n",
      "14934/14934 [==============================] - 177s 12ms/step - loss: 117.8969 - val_loss: 137.3586\n",
      "Epoch 5/100\n",
      "14934/14934 [==============================] - 207s 14ms/step - loss: 101.9389 - val_loss: 127.8354\n",
      "Epoch 6/100\n",
      "14934/14934 [==============================] - 173s 12ms/step - loss: 90.3267 - val_loss: 122.8448\n",
      "Epoch 7/100\n",
      "14934/14934 [==============================] - 181s 12ms/step - loss: 83.3346 - val_loss: 114.6787\n",
      "Epoch 8/100\n",
      "14934/14934 [==============================] - 206s 14ms/step - loss: 76.8126 - val_loss: 110.9939\n",
      "Epoch 9/100\n",
      "14934/14934 [==============================] - 192s 13ms/step - loss: 71.9608 - val_loss: 109.4016\n",
      "Epoch 10/100\n",
      "14934/14934 [==============================] - 171s 11ms/step - loss: 67.0924 - val_loss: 104.6340\n",
      "Epoch 11/100\n",
      "14934/14934 [==============================] - 208s 14ms/step - loss: 63.9036 - val_loss: 105.1813\n",
      "Epoch 12/100\n",
      "14934/14934 [==============================] - 193s 13ms/step - loss: 60.8339 - val_loss: 99.5629\n",
      "Epoch 13/100\n",
      "14934/14934 [==============================] - 173s 12ms/step - loss: 57.8423 - val_loss: 99.3991\n",
      "Epoch 14/100\n",
      "14934/14934 [==============================] - 207s 14ms/step - loss: 54.9797 - val_loss: 97.4080\n",
      "Epoch 15/100\n",
      "14934/14934 [==============================] - 198s 13ms/step - loss: 52.7595 - val_loss: 99.5785\n",
      "Epoch 16/100\n",
      "14934/14934 [==============================] - 216s 14ms/step - loss: 50.5060 - val_loss: 95.0217\n",
      "Epoch 17/100\n",
      "14934/14934 [==============================] - 200s 13ms/step - loss: 48.9591 - val_loss: 94.6340\n",
      "Epoch 18/100\n",
      "14934/14934 [==============================] - 192s 13ms/step - loss: 46.5461 - val_loss: 94.7503\n",
      "Epoch 19/100\n",
      "14934/14934 [==============================] - 178s 12ms/step - loss: 45.3211 - val_loss: 93.5231\n",
      "Epoch 20/100\n",
      "14934/14934 [==============================] - 183s 12ms/step - loss: 43.7718 - val_loss: 96.0296\n",
      "Epoch 21/100\n",
      "14934/14934 [==============================] - 188s 13ms/step - loss: 42.1098 - val_loss: 93.6258\n",
      "Epoch 22/100\n",
      "14934/14934 [==============================] - 209s 14ms/step - loss: 40.6947 - val_loss: 94.2104\n",
      "Epoch 23/100\n",
      "14934/14934 [==============================] - 175s 12ms/step - loss: 39.5145 - val_loss: 95.8260\n",
      "Epoch 24/100\n",
      "14934/14934 [==============================] - 187s 13ms/step - loss: 38.4800 - val_loss: 95.3569\n",
      "Epoch 25/100\n",
      "14934/14934 [==============================] - 189s 13ms/step - loss: 37.2493 - val_loss: 94.8091\n",
      "Epoch 26/100\n",
      "14934/14934 [==============================] - 185s 12ms/step - loss: 35.8462 - val_loss: 92.3604\n",
      "Epoch 27/100\n",
      "14934/14934 [==============================] - 188s 13ms/step - loss: 35.2922 - val_loss: 92.6679\n",
      "Epoch 28/100\n",
      "14934/14934 [==============================] - 186s 12ms/step - loss: 34.2012 - val_loss: 90.7438\n",
      "Epoch 29/100\n",
      "14934/14934 [==============================] - 188s 13ms/step - loss: 33.2124 - val_loss: 91.9709\n",
      "Epoch 30/100\n",
      "14934/14934 [==============================] - 188s 13ms/step - loss: 32.2725 - val_loss: 94.0803\n",
      "Epoch 31/100\n",
      "14934/14934 [==============================] - 190s 13ms/step - loss: 31.4387 - val_loss: 96.5234\n",
      "Epoch 32/100\n",
      "14934/14934 [==============================] - 197s 13ms/step - loss: 30.8823 - val_loss: 91.8659\n",
      "Epoch 33/100\n",
      "14934/14934 [==============================] - 180s 12ms/step - loss: 29.8446 - val_loss: 91.7248\n",
      "Epoch 34/100\n",
      "14934/14934 [==============================] - 191s 13ms/step - loss: 29.3334 - val_loss: 95.1807\n",
      "Epoch 35/100\n",
      "14934/14934 [==============================] - 192s 13ms/step - loss: 28.6490 - val_loss: 89.7379\n",
      "Epoch 36/100\n",
      "14934/14934 [==============================] - 193s 13ms/step - loss: 27.8786 - val_loss: 92.2691\n",
      "Epoch 37/100\n",
      "14934/14934 [==============================] - 235s 16ms/step - loss: 27.0910 - val_loss: 92.6832\n",
      "Epoch 38/100\n",
      "14934/14934 [==============================] - 196s 13ms/step - loss: 26.2822 - val_loss: 96.7270\n",
      "Epoch 39/100\n",
      "14934/14934 [==============================] - 189s 13ms/step - loss: 25.6372 - val_loss: 93.4500\n",
      "Epoch 40/100\n",
      "14934/14934 [==============================] - 191s 13ms/step - loss: 25.3837 - val_loss: 91.6259\n",
      "Epoch 41/100\n",
      "14934/14934 [==============================] - 190s 13ms/step - loss: 24.6766 - val_loss: 92.7931\n",
      "Epoch 42/100\n",
      "14934/14934 [==============================] - 191s 13ms/step - loss: 23.8368 - val_loss: 90.2625\n",
      "Epoch 43/100\n",
      "14934/14934 [==============================] - 188s 13ms/step - loss: 23.5606 - val_loss: 90.9449\n",
      "Epoch 44/100\n",
      "14934/14934 [==============================] - 240s 16ms/step - loss: 23.3597 - val_loss: 90.2385\n",
      "Epoch 45/100\n",
      "14934/14934 [==============================] - 159s 11ms/step - loss: 22.8251 - val_loss: 90.9544\n",
      "Epoch 46/100\n",
      "14934/14934 [==============================] - 240s 16ms/step - loss: 22.7116 - val_loss: 88.3079\n",
      "Epoch 47/100\n",
      "14934/14934 [==============================] - 162s 11ms/step - loss: 21.6827 - val_loss: 92.6098\n",
      "Epoch 48/100\n",
      "14934/14934 [==============================] - 196s 13ms/step - loss: 21.5281 - val_loss: 94.3441\n",
      "Epoch 49/100\n",
      "14934/14934 [==============================] - 233s 16ms/step - loss: 20.9558 - val_loss: 89.5034\n",
      "Epoch 50/100\n",
      "14934/14934 [==============================] - 164s 11ms/step - loss: 20.8208 - val_loss: 93.6738\n",
      "Epoch 51/100\n",
      "14934/14934 [==============================] - 191s 13ms/step - loss: 20.4237 - val_loss: 92.7740\n",
      "Epoch 52/100\n",
      "14934/14934 [==============================] - 200s 13ms/step - loss: 20.2878 - val_loss: 90.0950\n",
      "Epoch 53/100\n",
      "14934/14934 [==============================] - 208s 14ms/step - loss: 19.7756 - val_loss: 94.2251\n",
      "Epoch 54/100\n",
      "14934/14934 [==============================] - 211s 14ms/step - loss: 19.0840 - val_loss: 93.8925\n",
      "Epoch 55/100\n",
      "14934/14934 [==============================] - 189s 13ms/step - loss: 19.1346 - val_loss: 94.2744\n",
      "Epoch 56/100\n",
      "14934/14934 [==============================] - 230s 15ms/step - loss: 18.6215 - val_loss: 94.1828\n",
      "Epoch 57/100\n",
      "14934/14934 [==============================] - 159s 11ms/step - loss: 18.3889 - val_loss: 92.2049\n",
      "Epoch 58/100\n",
      "14934/14934 [==============================] - 182s 12ms/step - loss: 18.0280 - val_loss: 93.8295\n",
      "Epoch 59/100\n",
      "14934/14934 [==============================] - 186s 12ms/step - loss: 18.1698 - val_loss: 90.7621\n",
      "Epoch 60/100\n",
      "14934/14934 [==============================] - 183s 12ms/step - loss: 17.6009 - val_loss: 91.2436\n",
      "Epoch 61/100\n",
      "14934/14934 [==============================] - 210s 14ms/step - loss: 17.3058 - val_loss: 92.6915\n",
      "Epoch 62/100\n",
      "14934/14934 [==============================] - 184s 12ms/step - loss: 17.3137 - val_loss: 95.2417\n",
      "Epoch 63/100\n",
      "14934/14934 [==============================] - 239s 16ms/step - loss: 16.8505 - val_loss: 91.7202\n",
      "Epoch 64/100\n",
      "14934/14934 [==============================] - 168s 11ms/step - loss: 16.3604 - val_loss: 88.9992\n",
      "Epoch 65/100\n",
      "14934/14934 [==============================] - 203s 14ms/step - loss: 16.4319 - val_loss: 93.9697\n",
      "Epoch 66/100\n",
      "14934/14934 [==============================] - 225s 15ms/step - loss: 16.0879 - val_loss: 92.9334\n",
      "Epoch 67/100\n",
      "14934/14934 [==============================] - 199s 13ms/step - loss: 15.8690 - val_loss: 91.4556\n",
      "Epoch 68/100\n",
      "14934/14934 [==============================] - 216s 14ms/step - loss: 15.2324 - val_loss: 89.5067\n",
      "Epoch 69/100\n",
      "14934/14934 [==============================] - 207s 14ms/step - loss: 15.5651 - val_loss: 91.8766\n",
      "Epoch 70/100\n",
      "14934/14934 [==============================] - 181s 12ms/step - loss: 15.4245 - val_loss: 94.6902\n",
      "Epoch 71/100\n",
      "14934/14934 [==============================] - 185s 12ms/step - loss: 15.0715 - val_loss: 92.6329\n",
      "Epoch 72/100\n",
      "14934/14934 [==============================] - 217s 15ms/step - loss: 14.6699 - val_loss: 94.0762\n",
      "Epoch 73/100\n",
      "14934/14934 [==============================] - 186s 12ms/step - loss: 14.7777 - val_loss: 95.2375\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14934/14934 [==============================] - 189s 13ms/step - loss: 14.8337 - val_loss: 94.5552\n",
      "Epoch 75/100\n",
      "14934/14934 [==============================] - 181s 12ms/step - loss: 14.3468 - val_loss: 91.9334\n",
      "Epoch 76/100\n",
      "14934/14934 [==============================] - 183s 12ms/step - loss: 14.3989 - val_loss: 91.0028\n",
      "Epoch 77/100\n",
      "14934/14934 [==============================] - 230s 15ms/step - loss: 13.9169 - val_loss: 94.3424\n",
      "Epoch 78/100\n",
      "14934/14934 [==============================] - 175s 12ms/step - loss: 13.9364 - val_loss: 89.3069\n",
      "Epoch 79/100\n",
      "14934/14934 [==============================] - 164s 11ms/step - loss: 13.7734 - val_loss: 91.3889\n",
      "Epoch 80/100\n",
      "14934/14934 [==============================] - 209s 14ms/step - loss: 13.6716 - val_loss: 91.1616\n",
      "Epoch 81/100\n",
      "14934/14934 [==============================] - 176s 12ms/step - loss: 13.5292 - val_loss: 89.6739\n",
      "Epoch 82/100\n",
      "14934/14934 [==============================] - 241s 16ms/step - loss: 13.1173 - val_loss: 93.2396\n",
      "Epoch 83/100\n",
      "14934/14934 [==============================] - 163s 11ms/step - loss: 13.3791 - val_loss: 92.1274\n",
      "Epoch 84/100\n",
      "14934/14934 [==============================] - 198s 13ms/step - loss: 12.9478 - val_loss: 97.2217\n",
      "Epoch 85/100\n",
      "14934/14934 [==============================] - 188s 13ms/step - loss: 12.7097 - val_loss: 91.6239\n",
      "Epoch 86/100\n",
      "14934/14934 [==============================] - 193s 13ms/step - loss: 12.8528 - val_loss: 91.9170\n",
      "Epoch 87/100\n",
      "14934/14934 [==============================] - 191s 13ms/step - loss: 12.7431 - val_loss: 91.7745\n",
      "Epoch 88/100\n",
      "14934/14934 [==============================] - 202s 13ms/step - loss: 12.5221 - val_loss: 92.3275\n",
      "Epoch 89/100\n",
      "14934/14934 [==============================] - 192s 13ms/step - loss: 12.6145 - val_loss: 94.0921\n",
      "Epoch 90/100\n",
      "14934/14934 [==============================] - 196s 13ms/step - loss: 12.1709 - val_loss: 91.2687\n",
      "Epoch 91/100\n",
      "14934/14934 [==============================] - 203s 14ms/step - loss: 12.3632 - val_loss: 93.6467\n",
      "Epoch 92/100\n",
      "14934/14934 [==============================] - 211s 14ms/step - loss: 12.2366 - val_loss: 94.3872\n",
      "Epoch 93/100\n",
      "14934/14934 [==============================] - 187s 12ms/step - loss: 12.0533 - val_loss: 90.1253\n",
      "Epoch 94/100\n",
      "14934/14934 [==============================] - 191s 13ms/step - loss: 12.0880 - val_loss: 93.9089\n",
      "Epoch 95/100\n",
      "14934/14934 [==============================] - 236s 16ms/step - loss: 11.9516 - val_loss: 89.6601\n",
      "Epoch 96/100\n",
      "14934/14934 [==============================] - 161s 11ms/step - loss: 11.7465 - val_loss: 94.8989\n",
      "Epoch 97/100\n",
      "14934/14934 [==============================] - 227s 15ms/step - loss: 11.8840 - val_loss: 95.5194\n",
      "Epoch 98/100\n",
      "14934/14934 [==============================] - 252s 17ms/step - loss: 11.5029 - val_loss: 93.8072\n",
      "Epoch 99/100\n",
      "14934/14934 [==============================] - 252s 17ms/step - loss: 11.5553 - val_loss: 96.7975\n",
      "Epoch 100/100\n",
      "14934/14934 [==============================] - 187s 12ms/step - loss: 11.5324 - val_loss: 93.9423\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam (lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "ANCHORS = [5,5]\n",
    "BOX = 1\n",
    "ANCHORS_post = [2,5] ##MUDAR AQUI PARA [2,5]\n",
    "\n",
    "\n",
    "rede.compile(loss=ball_goalpost_loss3, optimizer=optimizer)\n",
    "\n",
    "\n",
    "rede.fit(x, y, validation_data = (x_val, y_val), epochs=100, batch_size=5)\n",
    "#existe tambem o validation split\n",
    "#validantion_data = (x_val,y_val)\n",
    "rede.compile(loss=mean_squared_error, optimizer='sgd', metrics = ['accuracy'])\n",
    "rede.save(pasta_atual+ '/Redepequena_colfax.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede = minha2_skip_pequena2(120,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14934 samples, validate on 1173 samples\n",
      "Epoch 1/100\n",
      "14934/14934 [==============================] - 263s 18ms/step - loss: 782.8944 - val_loss: 231.8965\n",
      "Epoch 2/100\n",
      "14934/14934 [==============================] - 300s 20ms/step - loss: 196.7309 - val_loss: 166.4851\n",
      "Epoch 3/100\n",
      "14934/14934 [==============================] - 319s 21ms/step - loss: 125.6179 - val_loss: 134.9971\n",
      "Epoch 4/100\n",
      "14934/14934 [==============================] - 305s 20ms/step - loss: 92.6767 - val_loss: 116.5461\n",
      "Epoch 5/100\n",
      "14934/14934 [==============================] - 333s 22ms/step - loss: 76.1336 - val_loss: 107.6614\n",
      "Epoch 6/100\n",
      "14934/14934 [==============================] - 296s 20ms/step - loss: 65.0209 - val_loss: 99.4285\n",
      "Epoch 7/100\n",
      "14934/14934 [==============================] - 287s 19ms/step - loss: 57.4418 - val_loss: 101.1006\n",
      "Epoch 8/100\n",
      "14934/14934 [==============================] - 329s 22ms/step - loss: 52.1071 - val_loss: 101.3221\n",
      "Epoch 9/100\n",
      "14934/14934 [==============================] - 332s 22ms/step - loss: 47.8800 - val_loss: 91.4816\n",
      "Epoch 10/100\n",
      "14934/14934 [==============================] - 254s 17ms/step - loss: 43.5305 - val_loss: 90.5800\n",
      "Epoch 11/100\n",
      "14934/14934 [==============================] - 292s 20ms/step - loss: 40.8678 - val_loss: 92.5117\n",
      "Epoch 12/100\n",
      "14934/14934 [==============================] - 252s 17ms/step - loss: 38.3311 - val_loss: 87.5908\n",
      "Epoch 13/100\n",
      "14934/14934 [==============================] - 311s 21ms/step - loss: 35.9193 - val_loss: 90.2050\n",
      "Epoch 14/100\n",
      "14934/14934 [==============================] - 302s 20ms/step - loss: 34.2298 - val_loss: 92.9708\n",
      "Epoch 15/100\n",
      "14934/14934 [==============================] - 331s 22ms/step - loss: 32.5129 - val_loss: 89.7487\n",
      "Epoch 16/100\n",
      "14934/14934 [==============================] - 280s 19ms/step - loss: 30.9626 - val_loss: 86.3473\n",
      "Epoch 17/100\n",
      "14934/14934 [==============================] - 336s 22ms/step - loss: 29.4693 - val_loss: 89.5243\n",
      "Epoch 18/100\n",
      "14934/14934 [==============================] - 340s 23ms/step - loss: 27.8829 - val_loss: 86.8691\n",
      "Epoch 19/100\n",
      "14934/14934 [==============================] - 338s 23ms/step - loss: 27.2270 - val_loss: 89.1618\n",
      "Epoch 20/100\n",
      "14934/14934 [==============================] - 339s 23ms/step - loss: 25.5713 - val_loss: 83.4992\n",
      "Epoch 21/100\n",
      "14934/14934 [==============================] - 339s 23ms/step - loss: 24.8613 - val_loss: 87.0512\n",
      "Epoch 22/100\n",
      "14934/14934 [==============================] - 335s 22ms/step - loss: 24.1094 - val_loss: 81.7708\n",
      "Epoch 23/100\n",
      "14934/14934 [==============================] - 274s 18ms/step - loss: 22.9578 - val_loss: 89.6300\n",
      "Epoch 24/100\n",
      "14934/14934 [==============================] - 341s 23ms/step - loss: 22.2162 - val_loss: 85.1134\n",
      "Epoch 25/100\n",
      "14934/14934 [==============================] - 341s 23ms/step - loss: 21.1520 - val_loss: 87.0160\n",
      "Epoch 26/100\n",
      "14934/14934 [==============================] - 266s 18ms/step - loss: 20.9000 - val_loss: 82.5530\n",
      "Epoch 27/100\n",
      "14934/14934 [==============================] - 339s 23ms/step - loss: 20.2005 - val_loss: 88.7162\n",
      "Epoch 28/100\n",
      "14934/14934 [==============================] - 339s 23ms/step - loss: 19.5231 - val_loss: 85.8744\n",
      "Epoch 29/100\n",
      "14934/14934 [==============================] - 340s 23ms/step - loss: 19.1344 - val_loss: 87.3027\n",
      "Epoch 30/100\n",
      "14934/14934 [==============================] - 289s 19ms/step - loss: 18.6989 - val_loss: 91.0561\n",
      "Epoch 31/100\n",
      "14934/14934 [==============================] - 289s 19ms/step - loss: 17.9113 - val_loss: 93.6788\n",
      "Epoch 32/100\n",
      "14934/14934 [==============================] - 337s 23ms/step - loss: 17.5170 - val_loss: 94.0651\n",
      "Epoch 33/100\n",
      "14934/14934 [==============================] - 275s 18ms/step - loss: 16.8562 - val_loss: 89.6133\n",
      "Epoch 34/100\n",
      "14934/14934 [==============================] - 311s 21ms/step - loss: 16.9289 - val_loss: 84.8854\n",
      "Epoch 35/100\n",
      "14934/14934 [==============================] - 309s 21ms/step - loss: 16.0316 - val_loss: 87.3891\n",
      "Epoch 36/100\n",
      "14934/14934 [==============================] - 333s 22ms/step - loss: 16.3284 - val_loss: 87.7104\n",
      "Epoch 37/100\n",
      "14934/14934 [==============================] - 290s 19ms/step - loss: 15.8110 - val_loss: 90.1448\n",
      "Epoch 38/100\n",
      "14934/14934 [==============================] - 330s 22ms/step - loss: 15.4372 - val_loss: 94.4196\n",
      "Epoch 39/100\n",
      "14934/14934 [==============================] - 309s 21ms/step - loss: 15.6072 - val_loss: 88.3517\n",
      "Epoch 40/100\n",
      "14934/14934 [==============================] - 271s 18ms/step - loss: 14.6185 - val_loss: 92.1717\n",
      "Epoch 41/100\n",
      "14934/14934 [==============================] - 314s 21ms/step - loss: 14.8735 - val_loss: 89.0150\n",
      "Epoch 42/100\n",
      "14934/14934 [==============================] - 445s 30ms/step - loss: 14.4041 - val_loss: 95.9880\n",
      "Epoch 43/100\n",
      "14934/14934 [==============================] - 257s 17ms/step - loss: 14.0695 - val_loss: 88.6344\n",
      "Epoch 44/100\n",
      "14934/14934 [==============================] - 324s 22ms/step - loss: 13.9444 - val_loss: 91.6692\n",
      "Epoch 45/100\n",
      "14934/14934 [==============================] - 304s 20ms/step - loss: 13.5444 - val_loss: 91.5888\n",
      "Epoch 46/100\n",
      "14934/14934 [==============================] - 323s 22ms/step - loss: 13.4390 - val_loss: 91.8834\n",
      "Epoch 47/100\n",
      "14934/14934 [==============================] - 296s 20ms/step - loss: 12.8984 - val_loss: 95.2885\n",
      "Epoch 48/100\n",
      "14934/14934 [==============================] - 311s 21ms/step - loss: 12.9685 - val_loss: 94.9156\n",
      "Epoch 49/100\n",
      "14934/14934 [==============================] - 449s 30ms/step - loss: 12.8356 - val_loss: 91.0544\n",
      "Epoch 50/100\n",
      "14934/14934 [==============================] - 323s 22ms/step - loss: 12.5011 - val_loss: 95.2373\n",
      "Epoch 51/100\n",
      "14934/14934 [==============================] - 292s 20ms/step - loss: 12.1253 - val_loss: 91.5192\n",
      "Epoch 52/100\n",
      "14934/14934 [==============================] - 334s 22ms/step - loss: 12.3745 - val_loss: 90.5343\n",
      "Epoch 53/100\n",
      "14934/14934 [==============================] - 327s 22ms/step - loss: 11.8733 - val_loss: 88.1279\n",
      "Epoch 54/100\n",
      "14934/14934 [==============================] - 319s 21ms/step - loss: 11.8285 - val_loss: 91.3812\n",
      "Epoch 55/100\n",
      "14934/14934 [==============================] - 321s 21ms/step - loss: 11.5309 - val_loss: 95.0575\n",
      "Epoch 56/100\n",
      "14934/14934 [==============================] - 420s 28ms/step - loss: 11.3671 - val_loss: 97.7935\n",
      "Epoch 57/100\n",
      "14934/14934 [==============================] - 320s 21ms/step - loss: 11.5205 - val_loss: 90.5512\n",
      "Epoch 58/100\n",
      "14934/14934 [==============================] - 321s 21ms/step - loss: 11.4048 - val_loss: 91.8596\n",
      "Epoch 59/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 10.9979 - val_loss: 91.5213\n",
      "Epoch 60/100\n",
      "14934/14934 [==============================] - 303s 20ms/step - loss: 10.8942 - val_loss: 88.4854\n",
      "Epoch 61/100\n",
      "14934/14934 [==============================] - 384s 26ms/step - loss: 10.5326 - val_loss: 92.3125\n",
      "Epoch 62/100\n",
      "14934/14934 [==============================] - 384s 26ms/step - loss: 11.1009 - val_loss: 89.4173\n",
      "Epoch 63/100\n",
      "14934/14934 [==============================] - 385s 26ms/step - loss: 10.3573 - val_loss: 97.1017\n",
      "Epoch 64/100\n",
      "14934/14934 [==============================] - 278s 19ms/step - loss: 10.4129 - val_loss: 89.4283\n",
      "Epoch 65/100\n",
      "14934/14934 [==============================] - 293s 20ms/step - loss: 10.4397 - val_loss: 96.4779\n",
      "Epoch 66/100\n",
      "14934/14934 [==============================] - 350s 23ms/step - loss: 10.2576 - val_loss: 96.9834\n",
      "Epoch 67/100\n",
      "14934/14934 [==============================] - 313s 21ms/step - loss: 9.9512 - val_loss: 92.2081\n",
      "Epoch 68/100\n",
      "14934/14934 [==============================] - 368s 25ms/step - loss: 10.2728 - val_loss: 90.4032\n",
      "Epoch 69/100\n",
      "14934/14934 [==============================] - 333s 22ms/step - loss: 9.8801 - val_loss: 95.9414\n",
      "Epoch 70/100\n",
      "14934/14934 [==============================] - 327s 22ms/step - loss: 9.8396 - val_loss: 91.0844\n",
      "Epoch 71/100\n",
      "14934/14934 [==============================] - 324s 22ms/step - loss: 9.9049 - val_loss: 93.2713\n",
      "Epoch 72/100\n",
      "14934/14934 [==============================] - 289s 19ms/step - loss: 9.6933 - val_loss: 87.2298\n",
      "Epoch 73/100\n",
      "14934/14934 [==============================] - 281s 19ms/step - loss: 9.6070 - val_loss: 89.7768\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14934/14934 [==============================] - 283s 19ms/step - loss: 9.6612 - val_loss: 94.6527\n",
      "Epoch 75/100\n",
      "14934/14934 [==============================] - 284s 19ms/step - loss: 9.3423 - val_loss: 92.2822\n",
      "Epoch 76/100\n",
      "14934/14934 [==============================] - 313s 21ms/step - loss: 9.6145 - val_loss: 91.7640\n",
      "Epoch 77/100\n",
      "14934/14934 [==============================] - 300s 20ms/step - loss: 9.2867 - val_loss: 97.0665\n",
      "Epoch 78/100\n",
      "14934/14934 [==============================] - 313s 21ms/step - loss: 8.9622 - val_loss: 90.9921\n",
      "Epoch 79/100\n",
      "14934/14934 [==============================] - 306s 21ms/step - loss: 9.0051 - val_loss: 86.7717\n",
      "Epoch 80/100\n",
      "14934/14934 [==============================] - 298s 20ms/step - loss: 9.2498 - val_loss: 88.6032\n",
      "Epoch 81/100\n",
      "14934/14934 [==============================] - 321s 22ms/step - loss: 8.4676 - val_loss: 92.7182\n",
      "Epoch 82/100\n",
      "14934/14934 [==============================] - 399s 27ms/step - loss: 8.8125 - val_loss: 91.1300\n",
      "Epoch 83/100\n",
      "14934/14934 [==============================] - 338s 23ms/step - loss: 8.5045 - val_loss: 88.7972\n",
      "Epoch 84/100\n",
      "14934/14934 [==============================] - 338s 23ms/step - loss: 8.8151 - val_loss: 90.9599\n",
      "Epoch 85/100\n",
      "14934/14934 [==============================] - 279s 19ms/step - loss: 8.5653 - val_loss: 93.3789\n",
      "Epoch 86/100\n",
      "14934/14934 [==============================] - 338s 23ms/step - loss: 8.4549 - val_loss: 99.7610\n",
      "Epoch 87/100\n",
      "14934/14934 [==============================] - 299s 20ms/step - loss: 8.4206 - val_loss: 93.2087\n",
      "Epoch 88/100\n",
      "14934/14934 [==============================] - 337s 23ms/step - loss: 8.2769 - val_loss: 96.3007\n",
      "Epoch 89/100\n",
      "14934/14934 [==============================] - 343s 23ms/step - loss: 8.4455 - val_loss: 92.2143\n",
      "Epoch 90/100\n",
      "14934/14934 [==============================] - 268s 18ms/step - loss: 8.0272 - val_loss: 87.6022\n",
      "Epoch 91/100\n",
      "14934/14934 [==============================] - 310s 21ms/step - loss: 8.0407 - val_loss: 90.3510\n",
      "Epoch 92/100\n",
      "14934/14934 [==============================] - 293s 20ms/step - loss: 7.9700 - val_loss: 92.0945\n",
      "Epoch 93/100\n",
      "14934/14934 [==============================] - 346s 23ms/step - loss: 8.0106 - val_loss: 94.9017\n",
      "Epoch 94/100\n",
      "14934/14934 [==============================] - 304s 20ms/step - loss: 7.9515 - val_loss: 90.8540\n",
      "Epoch 95/100\n",
      "14934/14934 [==============================] - 335s 22ms/step - loss: 7.9145 - val_loss: 87.6959\n",
      "Epoch 96/100\n",
      "14934/14934 [==============================] - 289s 19ms/step - loss: 7.7817 - val_loss: 87.7112\n",
      "Epoch 97/100\n",
      "14934/14934 [==============================] - 302s 20ms/step - loss: 7.9462 - val_loss: 84.3925\n",
      "Epoch 98/100\n",
      "14934/14934 [==============================] - 336s 23ms/step - loss: 7.5623 - val_loss: 96.3699\n",
      "Epoch 99/100\n",
      "14934/14934 [==============================] - 346s 23ms/step - loss: 7.6582 - val_loss: 91.1039\n",
      "Epoch 100/100\n",
      "14934/14934 [==============================] - 332s 22ms/step - loss: 7.6715 - val_loss: 84.6754\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam (lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "ANCHORS = [5,5]\n",
    "BOX = 1\n",
    "ANCHORS_post = [2,5] ##MUDAR AQUI PARA [2,5]\n",
    "\n",
    "\n",
    "rede.compile(loss=ball_goalpost_loss3, optimizer=optimizer)\n",
    "\n",
    "\n",
    "rede.fit(x, y, validation_data = (x_val, y_val), epochs=100, batch_size=5)\n",
    "#existe tambem o validation split\n",
    "#validantion_data = (x_val,y_val)\n",
    "rede.compile(loss=mean_squared_error, optimizer='sgd', metrics = ['accuracy'])\n",
    "rede.save(pasta_atual+ '/Rededeteste_colfax.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
